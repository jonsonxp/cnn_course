{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_DeepLearningSoftwareProgramming-Inference.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "## System Architecture 12 - Deep Learning Software Programming\n",
        "\n",
        "## (Part II) Model inference\n",
        "\n",
        "Author: Qian Zhao and Noriyuki Kushiro, Department of Computer Science and Networks, Kyushu Institute of Technology, 2020.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1rMC3z0oRqZ"
      },
      "source": [
        "After design and training of a nueual network, then we can use it in a real application. This jupyter notebook shows how to recognize a handwritten number use our LeNet-5 that trained with MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdLF9RGpoRqa"
      },
      "source": [
        "## Prepare: Python packages imported below are required.\n",
        "If you run the notebook on our prepared server, just push run button and enjoy.\n",
        "\n",
        "If you wish to run this notebook on your own computer, you have to prepare python enviroment with these packages installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "from time import time\n",
        "import os\n",
        "import warnings; warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5qiiny-oRqg"
      },
      "source": [
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1' #comment out this line if you want to use GPU\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU found')\n",
        "    !nvidia-smi\n",
        "else:\n",
        "    print(\"No GPU found, use CPU\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Ptoef5qPLa"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMdygmFUoRqj"
      },
      "source": [
        "## Step 1. Create model and load our trained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt7FrnproRqk"
      },
      "source": [
        "We use the same LeNet-5 network structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZt_nPIooRql"
      },
      "source": [
        "# LeNet-5 model as example\n",
        "class LeNet(Sequential):\n",
        "    def __init__(self, input_shape, nb_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
        "        self.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "        self.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
        "        self.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(120, activation='relu'))\n",
        "        self.add(Dense(84, activation='relu'))\n",
        "        self.add(Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "        self.compile(optimizer='adam',\n",
        "                    loss=categorical_crossentropy,\n",
        "                    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5x4yaeToRqn"
      },
      "source": [
        "First, create a model instance from LeNet class.\n",
        "\n",
        "For this time, we load weights from file, so we do not have to retrain all the parameters for use.\n",
        "\n",
        "Notice that, the neural network structure and its weights are a set. The weights is only meaningful for the same neural network from which it was exported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BPlTV3BoRqo"
      },
      "source": [
        "%%time\n",
        "\n",
        "model = LeNet((28, 28, 1), 10)\n",
        "\n",
        "#Load trained weights from file\n",
        "model.load_weights(\"my_lenet_mnist_model.weight\")\n",
        "\n",
        "#Confirm the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRdFx-lxoRqr"
      },
      "source": [
        "## Step 2. Draw a number with mouse as input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9tVAhuqoRqr"
      },
      "source": [
        "Now, lets test our neural network! Run the cell below, and draw a number in the paint canvas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YuE7zEnzU4d"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<div style=\"border: solid 2px #666; width: 143px; height: 144px; background: black;\">\n",
        "<canvas width=%d height=%d></canvas>\n",
        "</div>\n",
        "<button>Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "//ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "        if (e.buttons == 1) {\n",
        "            canvas.getContext(\"2d\").fillStyle = \"rgb(255,255,255)\";\n",
        "            canvas.getContext(\"2d\").fillRect(e.offsetX, e.offsetY, 8, 8);\n",
        "            x = Math.floor(e.offsetY * 0.2);\n",
        "            y = Math.floor(e.offsetX * 0.2) + 1;\n",
        "        }\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/jpeg', 0.75))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def draw(filename='handwrite.jpg', w=140, h=140, line_width=1):\n",
        "  display(HTML(canvas_html % (w, h, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "\n",
        "draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zcj1kHsPoRqw"
      },
      "source": [
        "Now the image data you drawed will be saved in a plaintext file \"handwrite.jpg\". You can confirm the content of this file from jupyter file lists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-zmmTROoRqw"
      },
      "source": [
        "## Step 3. Read input data from file and convert to tensor format for model input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KAwEy9noRqx"
      },
      "source": [
        "%%time\n",
        "#Load image handwrite.jpg\n",
        "img = np.array(Image.open('handwrite.jpg'))\n",
        "print(img.shape)\n",
        "\n",
        "#Convert color from RGB to GRAY\n",
        "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "print(img.shape)\n",
        "\n",
        "#Resize image to 28*28\n",
        "img = cv2.resize(img, dsize=(28, 28))\n",
        "print(img.shape)\n",
        "\n",
        "#Reshape array hand_data to a tensor format that match our model's input\n",
        "hand_input = np.array(img).reshape(1, 28,28,1)\n",
        "print(hand_input.shape)\n",
        "\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bV-6emMoRq0"
      },
      "source": [
        "## Step 4. Perform model inference and show prediction results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGKzccDHoRq1"
      },
      "source": [
        "Let's use our model recognize our handwritten number. It is very simple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIAwZE1ZoRq1"
      },
      "source": [
        "%%time\n",
        "#Do the model inference, predict the number from hand_input\n",
        "result = model.predict(hand_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTX1xhO5oRq5"
      },
      "source": [
        "Now all the prediction values are in the \"result\" variable. There are 10 numbers in \"result\", each of which means a class for a number from 0 ~ 9, and its value means the possibility that the input image belong to this class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WKyI2S9oRq5"
      },
      "source": [
        "%%time\n",
        "#Print predicted probability of 10 numbers (10 output classes of our model)\n",
        "print(result[0])\n",
        "\n",
        "#Show results in bar figure\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "subplot = fig.add_subplot(1,1,1)\n",
        "subplot.set_xticks(range(10))\n",
        "subplot.set_xlim(-0.5,9.5)\n",
        "subplot.bar(range(10), result[0], align='center')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYxljVWeoRq7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8H3m2cuoRq_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ZZ7QDRoRrB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}